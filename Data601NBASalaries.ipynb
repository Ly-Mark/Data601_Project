{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploration of NBA Salaries\n",
    "## Introduction\n",
    "\n",
    "The focus of our exploratory data analysis (EDA) will be on the salaries of athletes in the National Basketball Association (NBA).\n",
    "In exploring this data, we hope to examine how total salaries are divided amongst the teams and the allocation amongst\n",
    "players within certain teams. The earnings of top athletes are frequently addressed in the media and our team would like\n",
    "to explore the magnitude of the pay gap between top-performing teams and the best individual athletes relative to others.\n",
    "The salaries of athletes have drawn attention due to the announcement of large contracts for star players. Our team will\n",
    "provide an illustration of how these salaries have changed over the past 20 years. The growth rate in these metrics will\n",
    "be compared to wage growth data of the general public to see if there is significant divergence.\n",
    "\n",
    "## Guiding Questions\n",
    "\n",
    "1. How are the salaries of NBA players divided amongst the teams in the league and amongst the players within these teams?\n",
    "\n",
    "    In exploring this question, we would like to look at the allocation of the league overall and examine some constituent\n",
    "    teams, some containing star power and others which do not. In doing so, we would like to identify how the allocations\n",
    "    differ when there are star players on a team.\n",
    "\n",
    "\n",
    "2. Is there a significant correlation between the salaries paid and the success of a team?\n",
    "\n",
    "    This question would assist in determining whether higher pay leads to better performance and if the ability for a\n",
    "    team to succeed is dependent on the salaries paid.\n",
    "\n",
    "\n",
    "3. How are player salaries related to the position played? How have these changed over time?\n",
    "\n",
    "    Exploring these questions will identify if certain positions are more highly valued and provide insight into how\n",
    "    team compositions may change over time.\n",
    "\n",
    "\n",
    "4. How rapidly have salaries of NBA athletes increased over the past 20 years and how does this compare with average\n",
    "wage growth in the United States over the same period?\n",
    "\n",
    "    The contracts for certain athletes seem to grow faster than average wages. By studying the growth rate of the\n",
    "    athletes of the NBA compared to national labor statistics, we would like to see if there is a divergence.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "ESPN publishes NBA player salaries from 1990 to 2021. This page is organized in a structured table with headings for\n",
    "Rank, Name, Position, Team and Salary (USD). We will build and use a web scraper to pull this data into the same columns\n",
    "and export it into a comma separated file (CSV). ESPN is part of The Walt Disney Company.\n",
    "\n",
    "For the NBA team salaries, we will get the data from the website HoopsHype which is a website from USA Today Sports.\n",
    "HoopsHype has team salary data 1990 to 2021 which is organized and displayed in a structured html table with columns:\n",
    "Rank, Team, Salary (USD), and Salary adjusted for inflation (USD) using the U.S. Department of Labor Bureau of Labor Statistic.\n",
    "Again, we will be scraping by building a web scraper and export each year into CSV files. We will be stitching the\n",
    "multiple CSV files into a single one and wrangle the data usable for data analysis.\n",
    "\n",
    "For any additional player and game information we will be using the website basketball-reference.com. The information\n",
    "provided on this website is organized into structured tables which can be scraped if needed. Player data is separated\n",
    "into Regular season and a Playoff table with 30 columns that include: Season, Age, Team (Tm), League (Lg), Position (Pos),\n",
    "Games (G), Games Started (GS), Minutes played per game (MP), Field Goals per game (FG), Field Goal attempts per game (FGA),\n",
    "Field Goal percentage (FG%), 3-Points Field Goals per game (3P), 3-Point Field Goal attempts per game (3PA),\n",
    "3-Point Field Goal percentage (3P%), 2-Point Field Goals per game (2P), 2-Point Field Goal attempts per game (2PA),\n",
    "2-Point Field Goal percentage (2P%), Effective Field Goal percentage (eFG%), Free Throws per game (FT),\n",
    "Free Throw Attempts per game (FTA), Free Throw Percentage (FT%), Offensive Rebounds per game (ORB), Defensive Rounds per game (DRB),\n",
    "Total Rounds per game (TRB), Assists per game (AST), Steals per game (STL), Blocks per game (BLK), Turnovers  per game (TOV),\n",
    "Personal Fouls per game (PF), Points per game (PTS). These tables are available to download in a CSV format.\n",
    "Basketball-reference is owned and operated by Sports Reference LLC.\n",
    "\n",
    "Information on USA wages and salary growth will be retrieved from the website trading economics.com which uses\n",
    "information from the U.S Bureau of Economic Analysis. There are multiple indicators listed from 1960-2021 including\n",
    "age growth in percentage, Wages (USD/Hour) and Minimum Wages (USD/Hour) that we may use in our analysis.\n",
    "This data set is available to be downloaded as a CSV file or we can use the python API that they have provided.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "### Packages\n",
    "Pandas, Matplotlib, NumPy, requests, lxml, seaborn\n",
    "\n",
    "#### Web scraping\n",
    "For our web scraping function, we used the package *requests* to make HTTP requests to retrieve data from a specific URL.\n",
    "We will also need to make use of the *lxml* package, to handle XML and HTML tables. *Pandas* was used to convert the html\n",
    "tables to a data frame which makes it easier for data wrangling.\n",
    "\n",
    "#### Data Wrangling\n",
    "Our data still needs to be cleaned and organized to be able to do more EDA on our data. For this, we will use *Pandas*\n",
    "and *Numpy* packages. Tables retrieved from HoopsHype have extra characters in the table that need to be removed (\\n\\t,$).\n",
    "We will also need to stitch together multiple CSV files to a master CSV file and organize the dataframe by teams.\n",
    "For some of our visuals, we will need to filter our data based on players position which will completed\n",
    "using *Pandas* package. *Numpy* will be used for any additional calculations that and *Pandas* will be used to add those\n",
    "values to the dataframe.\n",
    "\n",
    "#### Visualization\n",
    "In order to create informative visuals, we will be applying different filters to our cleaned data. As our data consists\n",
    "of both individual player and team information, we will need to appropriately select subjects of interest. Time series\n",
    "data will likely be illustrated using a line graph but, we may consider other types if further insight may be gained.\n",
    "To show the allocation of salaries among teams in the league, a pie chart would provide a clear visual of this distribution.\n",
    "A bar of pie chart allows for more detailed inspection of specific teams from the overall set.\n",
    "\n",
    "We may also do some basic calculations in order to develop some visual comparisons. In examining the salaries based on\n",
    "position, we will calculate the mean/median for each player in the position during each season in order to develop a\n",
    "broader understanding of how the position played impacts the salary received.\n",
    "\n",
    "Following our exploration of the change in wages for both players in general as well as per position since 1991(?),\n",
    "we will hone in our focus on the wage discrepancy within teams currently. Three different datasets will be evaluated,\n",
    "each one representing a specific NBA team's salary sheet in the 2021-2022 season. Each team reflects a different\n",
    "perspective and philosophy of wage distribution in the league, which includes a team with one superstar, a well-rounded\n",
    "team with no dominant player and a team consisting of a mix of young players and role-players. We will calculate the\n",
    "mean, median, standard deviation as well as the percent of the total salary each player takes up to illuminate the\n",
    "distribution of wealth for each situation. Furthermore, a pie-chart will be utilized to visualize the data for each team,\n",
    "and each of these charts will be put side by side for comparison."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets\n",
    "\n",
    "## Webscraping function\n",
    "\n",
    "This webscraping function used to grab team salary data from 1990 - 2021 from https://hoopshype.com/salaries/2019-2020/\n",
    "The data presented on this website was from the HoopsHype's salary database and the adjusted for inflation data points\n",
    "were provided by Current US Dollars adjusted for inflation from data provided by the U.S.\n",
    "Department of Labor Bureau of Labor Statistic\n",
    "\n",
    "The function is based of the code from Syed Sadat Nazrul written for a tutorial on Web Scraping with python\n",
    "written on Jul 25,2018 https://towardsdatascience.com/web-scraping-html-tables-with-python-c9baba21059"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "def salary(url,year):\n",
    "    url=url\n",
    "    #Create a handle, page, to handle the contents of the website\n",
    "    page = requests.get(url)\n",
    "\n",
    "    #Store the contents of the website under doc\n",
    "    doc = lh.fromstring(page.content)\n",
    "\n",
    "    #Parse data that are stored between <tr>..</tr> of HTML\n",
    "    tr_elements = doc.xpath('//tr')\n",
    "\n",
    "    col = []\n",
    "    i=0\n",
    "\n",
    "    for t in tr_elements[0]:\n",
    "        i+=1\n",
    "        name=t.text_content()\n",
    "        print ('%d:\"%s\"'%(i,name))\n",
    "        col.append((name,[]))\n",
    "    for j in range(1,len(tr_elements)):\n",
    "        T=tr_elements[j]\n",
    "        if len(T)!=4:\n",
    "            break\n",
    "        i=0\n",
    "        for t in T.iterchildren():\n",
    "            data=t.text_content()\n",
    "            #check if row is empty\n",
    "            if i>0:\n",
    "                try:\n",
    "                    data=int(data)\n",
    "                except:\n",
    "                    pass\n",
    "            col[i][1].append(data)\n",
    "            i+=1\n",
    "\n",
    "    [len(c) for (title,c) in col]\n",
    "\n",
    "    dict = {title:column for (title,column)in col}\n",
    "    df=pd.DataFrame(dict)\n",
    "\n",
    "    team = df['Team'].str.strip('\\n\\t')\n",
    "    rank = df[''].str.strip('\\n\\t.')\n",
    "    salary = df.iloc[:,2].str.strip('\\n\\t$')\n",
    "    salary2 = df.iloc[:,3].str.strip('\\n\\t$')\n",
    "    year = [year]*27\n",
    "\n",
    "    teamSalary = pd.DataFrame({\n",
    "        \"rank\":rank[0:27],\n",
    "        \"team\":team[0:27],\n",
    "        \"salary\": salary[0:27],\n",
    "        \"salary(Inflation)\":salary2[0:27],\n",
    "        \"Year\":year\n",
    "    })\n",
    "    return teamSalary\n",
    "\n",
    "#df = salary(\"https://hoopshype.com/salaries/2020-2021/\",2021)\n",
    "#df.to_csv(r'D:\\UofC2021\\DATA601\\Project\\Data601_Project\\salary21.csv',index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data wrangling\n",
    "## Player data\n",
    "\n",
    "For player data we will be using the csv file that was scraped from the ESPN website. First, we will check for any\n",
    "missing data using a heatmap from the seaborn package. Missing values would have showed up as a yellow line.\n",
    "The original data csv data set has 10476 rows and 6 columns. To answer our third guiding question,\n",
    "How are player salaries related to the position played? How have these changed over time, we will only need to columns\n",
    "\"name\", \"position\", \"salary\", and \"season\". From this subset, we can further subset our data into the different basketball\n",
    "positions which are Center (C), Power Forward (PF), Small Forward (SF), Shooting Guard (SG), Point Guard (PG), Forward (F),\n",
    "and Guard (G). There are 2 other positions that were omitted which were Shooting Guard and Small forward (GF) and NA.\n",
    "There were only 57 of these players out of the 10476. We could have arbitrarily assigned the GF to either an SG or SF if\n",
    "there were more of those designations in the dataset. The NA's span from the 2002 season to the 2013 and have players\n",
    "that may have been demoted to the NBA-G which is their minor league or the NBA-D league for their development league during\n",
    "the season. Other reasons for these NA designations could be retirement, injuries or signings to international teams."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# creates a subset of the data where x data to be used, and pos is the position\n",
    "def makeSub(x,pos):\n",
    "    return x[x[\"position\"] == pos]\n",
    "\n",
    "\n",
    "# groups the position data by years and calculates the mean salary\n",
    "def meanCalc(x):\n",
    "    return (x.set_index('season')\n",
    "            .groupby(level=0).mean()\n",
    "            .rename(columns={\"salary\":\"mean salary\"}))\n",
    "\n",
    "\n",
    "# groups the position data by years and calculates the median salary\n",
    "def addMed(x):\n",
    "    return (x.set_index('season')\n",
    "            .groupby(level=0).median())\n",
    "\n",
    "# Original player data has 10476 rows and 6 columns\n",
    "position = pd.read_csv('nba-salaries.csv',\n",
    "                     usecols=['name','position','salary','season'])\n",
    "\n",
    "# using a heat map to check for any missing values\n",
    "sns.heatmap(position.isnull(),\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            cmap='viridis')\n",
    "\n",
    "# # subset of player data returning name, position, salary, and season\n",
    "# position = player[['name','position','salary','season']]\n",
    "\n",
    "#  separating the subset into the different basketball positions C, PF, SF, SG, PG, F, G\n",
    "cPosition = makeSub(position,\" C\") # 1996 rows\n",
    "pfPosition = makeSub(position, \" PF\") # 1771 rows\n",
    "sfPosition = makeSub(position, \" SF\") # 1558 rows\n",
    "sgPosition = makeSub(position, \" SG\") # 1671 rows\n",
    "pgPosition = makeSub(position, \" PG\") # 1542 rows\n",
    "fPosition = makeSub(position, \" F\") # 871 rows\n",
    "gPosition = makeSub(position, \" G\") # 1009 rows\n",
    "\n",
    "# center subset\n",
    "cMean = meanCalc(cPosition)\n",
    "cMean['median salary']= addMed(cPosition)\n",
    "\n",
    "# pf subset\n",
    "pfMean = meanCalc(pfPosition)\n",
    "pfMean['median salary']= addMed(pfPosition)\n",
    "\n",
    "# sf subset\n",
    "sfMean = meanCalc(sfPosition)\n",
    "sfMean['median salary']= addMed(sfPosition)\n",
    "\n",
    "# sg subset\n",
    "sgMean = meanCalc(sgPosition)\n",
    "sgMean['median salary']= addMed(sgPosition)\n",
    "\n",
    "# pg subset\n",
    "pgMean = meanCalc(pgPosition)\n",
    "pgMean['median salary']= addMed(pgPosition)\n",
    "\n",
    "# f subset\n",
    "fMean = meanCalc(fPosition)\n",
    "fMean['median salary']= addMed(fPosition)\n",
    "\n",
    "# g subset\n",
    "gMean = meanCalc(gPosition)\n",
    "gMean['median salary']= addMed(gPosition)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Team data\n",
    "We have multiple files for team data from Hypehoops.com which we will need to join in a single CSV.\n",
    "To do this more efficiently, we used the pack glob which finds all path names matching a specific pattern and returns\n",
    "them to an empty list. The result of this is that we can write a for loop to loop through each of the CSV files by name\n",
    "and run a pd.read_csv command instead of manually reading each of the files ourselves. To achieve this, we used the code\n",
    "from Gaurave Singh, that was posted on stack overflow on January 20, 2014\n",
    "https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "data": {
      "text/plain": "    rank           team     salary salary adjusted  Year           Team Conf  \\\n0     18      Cleveland  129605319       129605319  2021      Cleveland    E   \n1     19    San Antonio  129537825       129537825  2021    San Antonio    W   \n2     20        Toronto  129131910       129131910  2021        Toronto    E   \n3     21        Chicago  128963580       128963580  2021        Chicago    E   \n4     22        Phoenix  128858241       128858241  2021        Phoenix    W   \n5     30  Oklahoma City   95774839        95774839  2021  Oklahoma City    W   \n6     24        Orlando  121739163       121739163  2021        Orlando    E   \n7     25        Atlanta  118804016       118804016  2021        Atlanta    E   \n8     26        Detroit  117041599       117041599  2021        Detroit    E   \n9     27      Charlotte  108218809       108218809  2021      Charlotte    E   \n10    28     Sacramento  106847430       106847430  2021     Sacramento    W   \n11    17         Denver  129793210       129793210  2021         Denver    W   \n12    23         Dallas  127657823       127657823  2021         Dallas    W   \n13    16        Indiana  130237102       130237102  2021        Indiana    E   \n14     8          Miami  134731235       134731235  2021          Miami    E   \n15    14     Washington  131294012       131294012  2021     Washington    E   \n16    13        Houston  131784255       131784255  2021        Houston    W   \n17    12       Portland  131904647       131904647  2021       Portland    W   \n18    11        Memphis  132022601       132022601  2021        Memphis    W   \n19    10         Boston  132931565       132931565  2021         Boston    E   \n20     9    New Orleans  133901495       133901495  2021    New Orleans    W   \n21     7      Milwaukee  136623929       136623929  2021      Milwaukee    E   \n22     6           Utah  136881324       136881324  2021           Utah    W   \n23     5      LA Lakers  139334713       139334713  2021      LA Lakers    W   \n24     4    LA Clippers  139722606       139722606  2021    LA Clippers    W   \n25     3   Philadelphia  147825311       147825311  2021   Philadelphia    E   \n26     2       Brooklyn  170444633       170444633  2021       Brooklyn    E   \n27     1   Golden State  171105334       171105334  2021   Golden State    W   \n28    15      Minnesota  130334934       130334934  2021      Minnesota    W   \n29    29       New York  102137151       102137151  2021       New York    E   \n\n     W   L   W/L%  \n0   22  50  0.306  \n1   33  39  0.458  \n2   27  45  0.375  \n3   31  41  0.431  \n4   51  21  0.708  \n5   22  50  0.306  \n6   21  51  0.292  \n7   41  31  0.569  \n8   20  52  0.278  \n9   33  39  0.458  \n10  31  41  0.431  \n11  47  25  0.653  \n12  42  30  0.583  \n13  34  38  0.472  \n14  40  32  0.556  \n15  34  38  0.472  \n16  17  55  0.236  \n17  42  30  0.583  \n18  38  34  0.528  \n19  36  36  0.500  \n20  31  41  0.431  \n21  46  26  0.639  \n22  52  20  0.722  \n23  42  30  0.583  \n24  47  25  0.653  \n25  49  23  0.681  \n26  48  24  0.667  \n27  39  33  0.542  \n28  23  49  0.319  \n29  41  31  0.569  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>team</th>\n      <th>salary</th>\n      <th>salary adjusted</th>\n      <th>Year</th>\n      <th>Team</th>\n      <th>Conf</th>\n      <th>W</th>\n      <th>L</th>\n      <th>W/L%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18</td>\n      <td>Cleveland</td>\n      <td>129605319</td>\n      <td>129605319</td>\n      <td>2021</td>\n      <td>Cleveland</td>\n      <td>E</td>\n      <td>22</td>\n      <td>50</td>\n      <td>0.306</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19</td>\n      <td>San Antonio</td>\n      <td>129537825</td>\n      <td>129537825</td>\n      <td>2021</td>\n      <td>San Antonio</td>\n      <td>W</td>\n      <td>33</td>\n      <td>39</td>\n      <td>0.458</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>Toronto</td>\n      <td>129131910</td>\n      <td>129131910</td>\n      <td>2021</td>\n      <td>Toronto</td>\n      <td>E</td>\n      <td>27</td>\n      <td>45</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>Chicago</td>\n      <td>128963580</td>\n      <td>128963580</td>\n      <td>2021</td>\n      <td>Chicago</td>\n      <td>E</td>\n      <td>31</td>\n      <td>41</td>\n      <td>0.431</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22</td>\n      <td>Phoenix</td>\n      <td>128858241</td>\n      <td>128858241</td>\n      <td>2021</td>\n      <td>Phoenix</td>\n      <td>W</td>\n      <td>51</td>\n      <td>21</td>\n      <td>0.708</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>30</td>\n      <td>Oklahoma City</td>\n      <td>95774839</td>\n      <td>95774839</td>\n      <td>2021</td>\n      <td>Oklahoma City</td>\n      <td>W</td>\n      <td>22</td>\n      <td>50</td>\n      <td>0.306</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>24</td>\n      <td>Orlando</td>\n      <td>121739163</td>\n      <td>121739163</td>\n      <td>2021</td>\n      <td>Orlando</td>\n      <td>E</td>\n      <td>21</td>\n      <td>51</td>\n      <td>0.292</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>25</td>\n      <td>Atlanta</td>\n      <td>118804016</td>\n      <td>118804016</td>\n      <td>2021</td>\n      <td>Atlanta</td>\n      <td>E</td>\n      <td>41</td>\n      <td>31</td>\n      <td>0.569</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>26</td>\n      <td>Detroit</td>\n      <td>117041599</td>\n      <td>117041599</td>\n      <td>2021</td>\n      <td>Detroit</td>\n      <td>E</td>\n      <td>20</td>\n      <td>52</td>\n      <td>0.278</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>27</td>\n      <td>Charlotte</td>\n      <td>108218809</td>\n      <td>108218809</td>\n      <td>2021</td>\n      <td>Charlotte</td>\n      <td>E</td>\n      <td>33</td>\n      <td>39</td>\n      <td>0.458</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>28</td>\n      <td>Sacramento</td>\n      <td>106847430</td>\n      <td>106847430</td>\n      <td>2021</td>\n      <td>Sacramento</td>\n      <td>W</td>\n      <td>31</td>\n      <td>41</td>\n      <td>0.431</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>17</td>\n      <td>Denver</td>\n      <td>129793210</td>\n      <td>129793210</td>\n      <td>2021</td>\n      <td>Denver</td>\n      <td>W</td>\n      <td>47</td>\n      <td>25</td>\n      <td>0.653</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>23</td>\n      <td>Dallas</td>\n      <td>127657823</td>\n      <td>127657823</td>\n      <td>2021</td>\n      <td>Dallas</td>\n      <td>W</td>\n      <td>42</td>\n      <td>30</td>\n      <td>0.583</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>16</td>\n      <td>Indiana</td>\n      <td>130237102</td>\n      <td>130237102</td>\n      <td>2021</td>\n      <td>Indiana</td>\n      <td>E</td>\n      <td>34</td>\n      <td>38</td>\n      <td>0.472</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>8</td>\n      <td>Miami</td>\n      <td>134731235</td>\n      <td>134731235</td>\n      <td>2021</td>\n      <td>Miami</td>\n      <td>E</td>\n      <td>40</td>\n      <td>32</td>\n      <td>0.556</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14</td>\n      <td>Washington</td>\n      <td>131294012</td>\n      <td>131294012</td>\n      <td>2021</td>\n      <td>Washington</td>\n      <td>E</td>\n      <td>34</td>\n      <td>38</td>\n      <td>0.472</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>13</td>\n      <td>Houston</td>\n      <td>131784255</td>\n      <td>131784255</td>\n      <td>2021</td>\n      <td>Houston</td>\n      <td>W</td>\n      <td>17</td>\n      <td>55</td>\n      <td>0.236</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>12</td>\n      <td>Portland</td>\n      <td>131904647</td>\n      <td>131904647</td>\n      <td>2021</td>\n      <td>Portland</td>\n      <td>W</td>\n      <td>42</td>\n      <td>30</td>\n      <td>0.583</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>11</td>\n      <td>Memphis</td>\n      <td>132022601</td>\n      <td>132022601</td>\n      <td>2021</td>\n      <td>Memphis</td>\n      <td>W</td>\n      <td>38</td>\n      <td>34</td>\n      <td>0.528</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>10</td>\n      <td>Boston</td>\n      <td>132931565</td>\n      <td>132931565</td>\n      <td>2021</td>\n      <td>Boston</td>\n      <td>E</td>\n      <td>36</td>\n      <td>36</td>\n      <td>0.500</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>9</td>\n      <td>New Orleans</td>\n      <td>133901495</td>\n      <td>133901495</td>\n      <td>2021</td>\n      <td>New Orleans</td>\n      <td>W</td>\n      <td>31</td>\n      <td>41</td>\n      <td>0.431</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>7</td>\n      <td>Milwaukee</td>\n      <td>136623929</td>\n      <td>136623929</td>\n      <td>2021</td>\n      <td>Milwaukee</td>\n      <td>E</td>\n      <td>46</td>\n      <td>26</td>\n      <td>0.639</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>6</td>\n      <td>Utah</td>\n      <td>136881324</td>\n      <td>136881324</td>\n      <td>2021</td>\n      <td>Utah</td>\n      <td>W</td>\n      <td>52</td>\n      <td>20</td>\n      <td>0.722</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>5</td>\n      <td>LA Lakers</td>\n      <td>139334713</td>\n      <td>139334713</td>\n      <td>2021</td>\n      <td>LA Lakers</td>\n      <td>W</td>\n      <td>42</td>\n      <td>30</td>\n      <td>0.583</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4</td>\n      <td>LA Clippers</td>\n      <td>139722606</td>\n      <td>139722606</td>\n      <td>2021</td>\n      <td>LA Clippers</td>\n      <td>W</td>\n      <td>47</td>\n      <td>25</td>\n      <td>0.653</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3</td>\n      <td>Philadelphia</td>\n      <td>147825311</td>\n      <td>147825311</td>\n      <td>2021</td>\n      <td>Philadelphia</td>\n      <td>E</td>\n      <td>49</td>\n      <td>23</td>\n      <td>0.681</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2</td>\n      <td>Brooklyn</td>\n      <td>170444633</td>\n      <td>170444633</td>\n      <td>2021</td>\n      <td>Brooklyn</td>\n      <td>E</td>\n      <td>48</td>\n      <td>24</td>\n      <td>0.667</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1</td>\n      <td>Golden State</td>\n      <td>171105334</td>\n      <td>171105334</td>\n      <td>2021</td>\n      <td>Golden State</td>\n      <td>W</td>\n      <td>39</td>\n      <td>33</td>\n      <td>0.542</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>15</td>\n      <td>Minnesota</td>\n      <td>130334934</td>\n      <td>130334934</td>\n      <td>2021</td>\n      <td>Minnesota</td>\n      <td>W</td>\n      <td>23</td>\n      <td>49</td>\n      <td>0.319</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>New York</td>\n      <td>102137151</td>\n      <td>102137151</td>\n      <td>2021</td>\n      <td>New York</td>\n      <td>E</td>\n      <td>41</td>\n      <td>31</td>\n      <td>0.569</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "path = r'D:\\UofC2021\\DATA601\\Project\\Data601_Project\\teamSalary' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "teamData = pd.concat(li, axis=0, ignore_index=True)\n",
    "#exporting to csv to be used for another classes\n",
    "#teamData.to_csv(r'D:\\UofC2021\\DATA601\\Project\\Data601_Project\\teamSalary.csv',index = False)\n",
    "\n",
    "\n",
    "# removing commas from salary and salary(inflation), renamed, sorted\n",
    "teamData = (teamData.replace(',',\"\",regex=True)\n",
    "            .rename(columns={\"salary(Inflation)\":\"salary adjusted\"})\n",
    "            .sort_values(by=\"Year\"))\n",
    "\n",
    "teamData.set_index(['Year','team'])\n",
    "\n",
    "# win percentage from basketball reference.com\n",
    "win2021 = pd.read_csv('winpercent2021.csv',\n",
    "                      usecols=['Team','Conf','W','L','W/L%'])\n",
    "\n",
    "# Team salary data for the 2021 season\n",
    "team2021 = teamData[teamData[\"Year\"]==2021]\n",
    "\n",
    "team2021 = team2021.merge(win2021,how='left', left_on=\"team\", right_on=\"Team\")\n",
    "team2021"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e2177b6f",
   "language": "python",
   "display_name": "PyCharm (Homework)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}