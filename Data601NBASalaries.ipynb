{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploration of NBA Salaries\n",
    "## Introduction\n",
    "\n",
    "The focus of our exploratory data analysis (EDA) will be on the salaries of athletes in the National Basketball Association (NBA).\n",
    "In exploring this data, we hope to examine how total salaries are divided amongst the teams and the allocation amongst\n",
    "players within certain teams. The earnings of top athletes are frequently addressed in the media and our team would like\n",
    "to explore the magnitude of the pay gap between top-performing teams and the best individual athletes relative to others.\n",
    "The salaries of athletes have drawn attention due to the announcement of large contracts for star players. Our team will\n",
    "provide an illustration of how these salaries have changed over the past 20 years. The growth rate in these metrics will\n",
    "be compared to wage growth data of the general public to see if there is significant divergence.\n",
    "\n",
    "## Guiding Questions\n",
    "\n",
    "1. How are the salaries of NBA players divided amongst the teams in the league and amongst the players within these teams?\n",
    "\n",
    "    In exploring this question, we would like to look at the allocation of the league overall and examine some constituent\n",
    "    teams, some containing star power and others which do not. In doing so, we would like to identify how the allocations\n",
    "    differ when there are star players on a team.\n",
    "\n",
    "\n",
    "2. Is there a significant correlation between the salaries paid and the success of a team?\n",
    "\n",
    "    This question would assist in determining whether higher pay leads to better performance and if the ability for a\n",
    "    team to succeed is dependent on the salaries paid.\n",
    "\n",
    "\n",
    "3. How are player salaries related to the position played? How have these changed over time?\n",
    "\n",
    "    Exploring these questions will identify if certain positions are more highly valued and provide insight into how\n",
    "    team compositions may change over time.\n",
    "\n",
    "\n",
    "4. How rapidly have salaries of NBA athletes increased over the past 20 years and how does this compare with average\n",
    "wage growth in the United States over the same period?\n",
    "\n",
    "    The contracts for certain athletes seem to grow faster than average wages. By studying the growth rate of the\n",
    "    athletes of the NBA compared to national labor statistics, we would like to see if there is a divergence.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "ESPN publishes NBA player salaries from 1990 to 2021. This page is organized in a structured table with headings for\n",
    "Rank, Name, Position, Team and Salary (USD). We will build and use a web scraper to pull this data into the same columns\n",
    "and export it into a comma separated file (CSV). ESPN is part of The Walt Disney Company.\n",
    "\n",
    "For the NBA team salaries, we will get the data from the website HoopsHype which is a website from USA Today Sports.\n",
    "HoopsHype has team salary data 1990 to 2021 which is organized and displayed in a structured html table with columns:\n",
    "Rank, Team, Salary (USD), and Salary adjusted for inflation (USD) using the U.S. Department of Labor Bureau of Labor Statistic.\n",
    "Again, we will be scraping by building a web scraper and export each year into CSV files. We will be stitching the\n",
    "multiple CSV files into a single one and wrangle the data usable for data analysis.\n",
    "\n",
    "For any additional player and game information we will be using the website basketball-reference.com. The information\n",
    "provided on this website is organized into structured tables which can be scraped if needed. Player data is separated\n",
    "into Regular season and a Playoff table with 30 columns that include: Season, Age, Team (Tm), League (Lg), Position (Pos),\n",
    "Games (G), Games Started (GS), Minutes played per game (MP), Field Goals per game (FG), Field Goal attempts per game (FGA),\n",
    "Field Goal percentage (FG%), 3-Points Field Goals per game (3P), 3-Point Field Goal attempts per game (3PA),\n",
    "3-Point Field Goal percentage (3P%), 2-Point Field Goals per game (2P), 2-Point Field Goal attempts per game (2PA),\n",
    "2-Point Field Goal percentage (2P%), Effective Field Goal percentage (eFG%), Free Throws per game (FT),\n",
    "Free Throw Attempts per game (FTA), Free Throw Percentage (FT%), Offensive Rebounds per game (ORB), Defensive Rounds per game (DRB),\n",
    "Total Rounds per game (TRB), Assists per game (AST), Steals per game (STL), Blocks per game (BLK), Turnovers  per game (TOV),\n",
    "Personal Fouls per game (PF), Points per game (PTS). These tables are available to download in a CSV format.\n",
    "Basketball-reference is owned and operated by Sports Reference LLC.\n",
    "\n",
    "Information on USA wages and salary growth will be retrieved from the website trading economics.com which uses\n",
    "information from the U.S Bureau of Economic Analysis. There are multiple indicators listed from 1960-2021 including\n",
    "age growth in percentage, Wages (USD/Hour) and Minimum Wages (USD/Hour) that we may use in our analysis.\n",
    "This data set is available to be downloaded as a CSV file or we can use the python API that they have provided.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "### Packages\n",
    "Pandas, Matplotlib, NumPy, requests, lxml, seaborn\n",
    "\n",
    "#### Web scraping\n",
    "For our web scraping function, we used the package *requests* to make HTTP requests to retrieve data from a specific URL.\n",
    "We will also need to make use of the *lxml* package, to handle XML and HTML tables. *Pandas* was used to convert the html\n",
    "tables to a data frame which makes it easier for data wrangling.\n",
    "\n",
    "#### Data Wrangling\n",
    "Our data still needs to be cleaned and organized to be able to do more EDA on our data. For this, we will use *Pandas*\n",
    "and *Numpy* packages. Tables retrieved from HoopsHype have extra characters in the table that need to be removed (\\n\\t,$).\n",
    "We will also need to stitch together multiple CSV files to a master CSV file and organize the dataframe by teams.\n",
    "For some of our visuals, we will need to filter our data based on players position which will completed\n",
    "using *Pandas* package. *Numpy* will be used for any additional calculations that and *Pandas* will be used to add those\n",
    "values to the dataframe.\n",
    "\n",
    "#### Visualization\n",
    "In order to create informative visuals, we will be applying different filters to our cleaned data. As our data consists\n",
    "of both individual player and team information, we will need to appropriately select subjects of interest. Time series\n",
    "data will likely be illustrated using a line graph but, we may consider other types if further insight may be gained.\n",
    "To show the allocation of salaries among teams in the league, a pie chart would provide a clear visual of this distribution.\n",
    "A bar of pie chart allows for more detailed inspection of specific teams from the overall set.\n",
    "\n",
    "We may also do some basic calculations in order to develop some visual comparisons. In examining the salaries based on\n",
    "position, we will calculate the mean/median for each player in the position during each season in order to develop a\n",
    "broader understanding of how the position played impacts the salary received.\n",
    "\n",
    "Following our exploration of the change in wages for both players in general as well as per position since 1991(?),\n",
    "we will hone in our focus on the wage discrepancy within teams currently. Three different datasets will be evaluated,\n",
    "each one representing a specific NBA team's salary sheet in the 2021-2022 season. Each team reflects a different\n",
    "perspective and philosophy of wage distribution in the league, which includes a team with one superstar, a well-rounded\n",
    "team with no dominant player and a team consisting of a mix of young players and role-players. We will calculate the\n",
    "mean, median, standard deviation as well as the percent of the total salary each player takes up to illuminate the\n",
    "distribution of wealth for each situation. Furthermore, a pie-chart will be utilized to visualize the data for each team,\n",
    "and each of these charts will be put side by side for comparison."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets\n",
    "\n",
    "## Webscraping function\n",
    "\n",
    "This webscraping function used to grab team salary data from 1990 - 2021 from https://hoopshype.com/salaries/2019-2020/\n",
    "The data presented on this website was from the HoopsHype's salary database and the adjusted for inflation data points\n",
    "were provided by Current US Dollars adjusted for inflation from data provided by the U.S.\n",
    "Department of Labor Bureau of Labor Statistic\n",
    "\n",
    "The function is based of the code from Syed Sadat Nazrul written for a tutorial on Web Scraping with python\n",
    "written on Jul 25,2018 https://towardsdatascience.com/web-scraping-html-tables-with-python-c9baba21059"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "def salary(url,year):\n",
    "    url=url\n",
    "    #Create a handle, page, to handle the contents of the website\n",
    "    page = requests.get(url)\n",
    "\n",
    "    #Store the contents of the website under doc\n",
    "    doc = lh.fromstring(page.content)\n",
    "\n",
    "    #Parse data that are stored between <tr>..</tr> of HTML\n",
    "    tr_elements = doc.xpath('//tr')\n",
    "\n",
    "    col = []\n",
    "    i=0\n",
    "\n",
    "    for t in tr_elements[0]:\n",
    "        i+=1\n",
    "        name=t.text_content()\n",
    "        print ('%d:\"%s\"'%(i,name))\n",
    "        col.append((name,[]))\n",
    "    for j in range(1,len(tr_elements)):\n",
    "        T=tr_elements[j]\n",
    "        if len(T)!=4:\n",
    "            break\n",
    "        i=0\n",
    "        for t in T.iterchildren():\n",
    "            data=t.text_content()\n",
    "            #check if row is empty\n",
    "            if i>0:\n",
    "                try:\n",
    "                    data=int(data)\n",
    "                except:\n",
    "                    pass\n",
    "            col[i][1].append(data)\n",
    "            i+=1\n",
    "\n",
    "    [len(c) for (title,c) in col]\n",
    "\n",
    "    dict = {title:column for (title,column)in col}\n",
    "    df=pd.DataFrame(dict)\n",
    "\n",
    "    team = df['Team'].str.strip('\\n\\t')\n",
    "    rank = df[''].str.strip('\\n\\t.')\n",
    "    salary = df.iloc[:,2].str.strip('\\n\\t$')\n",
    "    salary2 = df.iloc[:,3].str.strip('\\n\\t$')\n",
    "    year = [year]*27\n",
    "\n",
    "    teamSalary = pd.DataFrame({\n",
    "        \"rank\":rank[0:27],\n",
    "        \"team\":team[0:27],\n",
    "        \"salary\": salary[0:27],\n",
    "        \"salary(Inflation)\":salary2[0:27],\n",
    "        \"Year\":year\n",
    "    })\n",
    "    return teamSalary\n",
    "\n",
    "#df = salary(\"https://hoopshype.com/salaries/2020-2021/\",2021)\n",
    "#df.to_csv(r'D:\\UofC2021\\DATA601\\Project\\Data601_Project\\salary21.csv',index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data wrangling\n",
    "## Player data\n",
    "\n",
    "For player data we will be using the csv file that was scraped from the ESPN website. First, we will check for any\n",
    "missing data using a heatmap from the seaborn package. Missing values would have showed up as a yellow line.\n",
    "The original data csv data set has 10476 rows and 6 columns. To answer our third guiding question,\n",
    "How are player salaries related to the position played? How have these changed over time, we will only need to columns\n",
    "\"name\", \"position\", \"salary\", and \"season\". From this subset, we can further subset our data into the different basketball\n",
    "positions which are Center (C), Power Forward (PF), Small Forward (SF), Shooting Guard (SG), Point Guard (PG), Forward (F),\n",
    "and Guard (G). There are 2 other positions that were omitted which were Shooting Guard and Small forward (GF) and NA.\n",
    "There were only 57 of these players out of the 10476. We could have arbitrarily assigned the GF to either an SG or SF if\n",
    "there were more of those designations in the dataset. The NA's span from the 2002 season to the 2013 and have players\n",
    "that may have been demoted to the NBA-G which is their minor league or the NBA-D league for their development league during\n",
    "the season. Other reasons for these NA designations could be retirement, injuries or signings to international teams."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# creates a subset of the data where x data to be used, and pos is the position\n",
    "def makeSub(x,pos):\n",
    "    return x[x[\"position\"] == pos]\n",
    "\n",
    "\n",
    "# groups the position data by years and calculates the mean salary\n",
    "def meanCalc(x):\n",
    "    return (x.set_index('season')\n",
    "            .groupby(level=0).mean()\n",
    "            .rename(columns={\"salary\":\"mean salary\"}))\n",
    "\n",
    "\n",
    "# groups the position data by years and calculates the median salary\n",
    "def addMed(x):\n",
    "    return (x.set_index('season')\n",
    "            .groupby(level=0).median())\n",
    "\n",
    "# Original player data has 10476 rows and 6 columns\n",
    "position = pd.read_csv('nba-salaries.csv',\n",
    "                     usecols=['name','position','salary','season'])\n",
    "\n",
    "# using a heat map to check for any missing values\n",
    "sns.heatmap(position.isnull(),\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            cmap='viridis')\n",
    "\n",
    "# # subset of player data returning name, position, salary, and season\n",
    "# position = player[['name','position','salary','season']]\n",
    "\n",
    "#  separating the subset into the different basketball positions C, PF, SF, SG, PG, F, G\n",
    "cPosition = makeSub(position,\" C\") # 1996 rows\n",
    "pfPosition = makeSub(position, \" PF\") # 1771 rows\n",
    "sfPosition = makeSub(position, \" SF\") # 1558 rows\n",
    "sgPosition = makeSub(position, \" SG\") # 1671 rows\n",
    "pgPosition = makeSub(position, \" PG\") # 1542 rows\n",
    "fPosition = makeSub(position, \" F\") # 871 rows\n",
    "gPosition = makeSub(position, \" G\") # 1009 rows\n",
    "\n",
    "# center subset\n",
    "cMean = meanCalc(cPosition)\n",
    "cMean['median salary']= addMed(cPosition)\n",
    "\n",
    "# pf subset\n",
    "pfMean = meanCalc(pfPosition)\n",
    "pfMean['median salary']= addMed(pfPosition)\n",
    "\n",
    "# sf subset\n",
    "sfMean = meanCalc(sfPosition)\n",
    "sfMean['median salary']= addMed(sfPosition)\n",
    "\n",
    "# sg subset\n",
    "sgMean = meanCalc(sgPosition)\n",
    "sgMean['median salary']= addMed(sgPosition)\n",
    "\n",
    "# pg subset\n",
    "pgMean = meanCalc(pgPosition)\n",
    "pgMean['median salary']= addMed(pgPosition)\n",
    "\n",
    "# f subset\n",
    "fMean = meanCalc(fPosition)\n",
    "fMean['median salary']= addMed(fPosition)\n",
    "\n",
    "# g subset\n",
    "gMean = meanCalc(gPosition)\n",
    "gMean['median salary']= addMed(gPosition)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Team data\n",
    "We have multiple files for team data from Hypehoops.com which we will need to join in a single CSV.\n",
    "To do this more efficiently, we used the pack glob which finds all path names matching a specific pattern and returns\n",
    "them to an empty list. The result of this is that we can write a for loop to loop through each of the CSV files by name\n",
    "and run a pd.read_csv command instead of manually reading each of the files ourselves. To achieve this, we used the code\n",
    "from Gaurave Singh, that was posted on stack overflow on January 20, 2014\n",
    "https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "                   rank     salary salary adjusted\nYear team                                         \n1991 Orlando         27    7532000        14947853\n     Minnesota       26    7540000        14963731\n     Miami           25    8510000        16888774\n     Sacramento      24    9605000        19061891\n     Washington      23    9610000        19071812\n...                 ...        ...             ...\n2021 Philadelphia     3  147825311       147825311\n     Brooklyn         2  170444633       170444633\n     Charlotte       27  108218809       108218809\n     Houston         13  131784255       131784255\n     Detroit         26  117041599       117041599\n\n[837 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>rank</th>\n      <th>salary</th>\n      <th>salary adjusted</th>\n    </tr>\n    <tr>\n      <th>Year</th>\n      <th>team</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1991</th>\n      <th>Orlando</th>\n      <td>27</td>\n      <td>7532000</td>\n      <td>14947853</td>\n    </tr>\n    <tr>\n      <th>Minnesota</th>\n      <td>26</td>\n      <td>7540000</td>\n      <td>14963731</td>\n    </tr>\n    <tr>\n      <th>Miami</th>\n      <td>25</td>\n      <td>8510000</td>\n      <td>16888774</td>\n    </tr>\n    <tr>\n      <th>Sacramento</th>\n      <td>24</td>\n      <td>9605000</td>\n      <td>19061891</td>\n    </tr>\n    <tr>\n      <th>Washington</th>\n      <td>23</td>\n      <td>9610000</td>\n      <td>19071812</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">2021</th>\n      <th>Philadelphia</th>\n      <td>3</td>\n      <td>147825311</td>\n      <td>147825311</td>\n    </tr>\n    <tr>\n      <th>Brooklyn</th>\n      <td>2</td>\n      <td>170444633</td>\n      <td>170444633</td>\n    </tr>\n    <tr>\n      <th>Charlotte</th>\n      <td>27</td>\n      <td>108218809</td>\n      <td>108218809</td>\n    </tr>\n    <tr>\n      <th>Houston</th>\n      <td>13</td>\n      <td>131784255</td>\n      <td>131784255</td>\n    </tr>\n    <tr>\n      <th>Detroit</th>\n      <td>26</td>\n      <td>117041599</td>\n      <td>117041599</td>\n    </tr>\n  </tbody>\n</table>\n<p>837 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "path = r'D:\\UofC2021\\DATA601\\Project\\Data601_Project\\teamSalary' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "teamData = pd.concat(li, axis=0, ignore_index=True)\n",
    "#exporting to csv to be used for another classes\n",
    "#teamData.to_csv(r'D:\\UofC2021\\DATA601\\Project\\Data601_Project\\teamSalary.csv',index = False)\n",
    "\n",
    "\n",
    "# removing commas from salary and salary(inflation), renamed, sorted\n",
    "teamData = (teamData.replace(',',\"\",regex=True)\n",
    "            .rename(columns={\"salary(Inflation)\":\"salary adjusted\"})\n",
    "            .sort_values(by=\"Year\"))\n",
    "\n",
    "teamData.set_index(['Year','team'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e2177b6f",
   "language": "python",
   "display_name": "PyCharm (Homework)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}